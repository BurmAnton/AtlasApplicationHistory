## Скрипт для автоматического импорта выгрузок из Атлас

### Требования

- Установленный браузер Chrome или Edge.
- Установлены зависимости из `requirements.txt` (в том числе `selenium`, `webdriver-manager`, `PyYAML`).

### Настройка конфигурации

В корне проекта находится файл `scraper_config.yaml`. В нём нужно указать:

- `auth` — адрес страницы логина, логин/пароль и CSS‑селекторы полей и кнопки входа.
- `pages` — URL страницы, где доступен экспорт, текст пункта меню/ссылки «Экспорт по выбранным фильтрам» и селектор модального окна.
- `modal` — селекторы контейнера списка выгрузок, отдельного элемента списка, текста (с датой/временем) и кнопки скачивания.
- `browser` — тип драйвера (`chrome` или `edge`), папка загрузки файлов, таймауты и максимальное количество прокруток.

Пример структуры см. в самом файле `scraper_config.yaml`.

### Запуск скрапера

Команда для запуска из корня проекта:

```bash
python manage.py fetch_exports
```

Дополнительные параметры:

- `--config path/to/config.yaml` — путь к альтернативному конфигу.
- `--limit N` — ограничить количество выгрузок, которые будут скачаны и импортированы за один запуск.

Скрапер:

1. Авторизуется на платформе.
2. Открывает страницу экспорта и модальное окно «Экспорт по выбранным фильтрам».
3. Прокручивает историю выгрузок до конца.
4. Скачивает все найденные файлы.
5. Для каждого файла вызывает существующую логику импорта (`import_from_file`), которая обновляет заявки и записывает историю импортов.


